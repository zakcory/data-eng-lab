{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T00:21:27.912347400Z",
     "start_time": "2024-07-15T00:21:19.533317100Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.debug.set_debug at 0x7f90db269710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "torch_geometric.set_debug(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136140db7336aab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d18827d45c082",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8991848c218eb533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T00:25:17.172389200Z",
     "start_time": "2024-07-15T00:25:17.140863300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(nodes_df_path, edges_df_path, subject_mapping_path):\n",
    "    nodes_df = pd.read_csv(nodes_df_path)\n",
    "    edges_df = pd.read_csv(edges_df_path)\n",
    "    with open(subject_mapping_path, 'rb') as f:\n",
    "        subject_mapping = pickle.load(f)\n",
    "    return nodes_df, edges_df, subject_mapping\n",
    "\n",
    "\n",
    "def get_node_id_mapping(nodes_df):\n",
    "    node_id_mapping, inverse_node_id_mapping = dict(), dict()\n",
    "    for i, node_id in enumerate(nodes_df['nodeId']):\n",
    "        node_id_mapping[i] = node_id\n",
    "        inverse_node_id_mapping[node_id] = i\n",
    "    return node_id_mapping, inverse_node_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d741f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodeId</th>\n",
       "      <th>subject</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31336</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061127</td>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106406</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13195</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37879</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>1128975</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>1128977</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>1128978</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>117328</td>\n",
       "      <td>Case_Based</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>24043</td>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nodeId                 subject  \\\n",
       "0       31336         Neural_Networks   \n",
       "1     1061127           Rule_Learning   \n",
       "2     1106406  Reinforcement_Learning   \n",
       "3       13195  Reinforcement_Learning   \n",
       "4       37879   Probabilistic_Methods   \n",
       "...       ...                     ...   \n",
       "2703  1128975      Genetic_Algorithms   \n",
       "2704  1128977      Genetic_Algorithms   \n",
       "2705  1128978      Genetic_Algorithms   \n",
       "2706   117328              Case_Based   \n",
       "2707    24043         Neural_Networks   \n",
       "\n",
       "                                               features  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2703  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2704  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2705  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2706  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2707  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2708 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6253a74469198dfa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_vectors(nodes_df):\n",
    "    features = nodes_df['features'].apply((lambda x: x.strip('][').split(', ')))\n",
    "    features = np.array([[float(val) for val in feature] for feature in features])\n",
    "    return torch.from_numpy(features).to(torch.double)\n",
    "\n",
    "\n",
    "def get_edges(edges_df, id_mapping):\n",
    "    source_labels = edges_df['sourceNodeId'].apply(lambda x: id_mapping[x]).to_numpy()\n",
    "    target_labels = edges_df['targetNodeId'].apply(lambda x: id_mapping[x]).to_numpy()\n",
    "    edges_indices = np.stack((source_labels, target_labels), axis=0)\n",
    "    return torch.from_numpy(edges_indices)\n",
    "\n",
    "\n",
    "def get_labels(nodes_df, subject_mapping):\n",
    "    labels = nodes_df['subject'].apply(lambda x: subject_mapping[x]).to_numpy()\n",
    "    return torch.from_numpy(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebc6262a706663",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2990d42fb3fb06aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T00:25:18.599753700Z",
     "start_time": "2024-07-15T00:25:18.441126100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_df_path = 'nodes.csv'\n",
    "edges_df_path = 'edges.csv'\n",
    "subject_mapping_path = 'subject_mapping.pkl'\n",
    "nodes_df, edges_df, subject_mapping = read_data(nodes_df_path, edges_df_path, subject_mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84eb6ec8c176a408",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_id_mapping, inverse_node_id_mapping = get_node_id_mapping(nodes_df)\n",
    "# TODO: These functions need to be implemented. You can decide what are the input arguments to these functions.\n",
    "x = get_feature_vectors(nodes_df)\n",
    "edge_index = get_edges(edges_df, inverse_node_id_mapping)\n",
    "y = get_labels(nodes_df, subject_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd2655ccbe7fb0d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('indices_dict_part2.pkl', 'rb') as f:\n",
    "    indices_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1a0eded454dcceb9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mask = torch.tensor([1 if node_id_mapping[i] in indices_dict['train_indices'] else 0 for i in range(x.shape[0])], dtype=torch.bool)\n",
    "valid_mask = torch.tensor([1 if node_id_mapping[i] in indices_dict['valid_indices'] else 0 for i in range(x.shape[0])], dtype=torch.bool)\n",
    "test_mask = torch.tensor([1 if node_id_mapping[i] in indices_dict['test_indices'] else 0 for i in range(x.shape[0])], dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d6223faffd4f9c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(x=x.float(), y=y, edge_index=edge_index, train_mask=train_mask, valid_mask=valid_mask, test_mask=test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0a673d4c35320",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b5ec05507e2191a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, output_dim, seed):\n",
    "        super().__init__()\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        self.conv1 = SAGEConv(in_channels=hidden_channels, out_channels=hidden_channels)\n",
    "        self.conv2 = SAGEConv(in_channels=hidden_channels, out_channels=output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb36dc1de13f2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b0893059e6c29aca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_dim = len(subject_mapping)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5bd270ed6ebc396d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(best_model, rel_mask):\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = best_model(data.x, data.edge_index).argmax(dim=1)\n",
    "        correct = (preds[rel_mask] == data.y[rel_mask]).sum()\n",
    "        return round(int(correct) / int(rel_mask.sum()), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af409902fac89678",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data, num_epochs=100, save_path='best_model.pt'):\n",
    "    loss_steps = list()\n",
    "    best_val_acc = 0\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_acc = evaluate(model, data.valid_mask)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "        if epoch % 20 == 0 or epoch == 1:\n",
    "            print(f\"Epoch: {epoch:03d}  \"\n",
    "                  f\"Best Val Acc: {best_val_acc:.4f}  \"\n",
    "                  f\"Best Loss: {best_loss:.4f}  \"\n",
    "            )\n",
    "        loss_steps.append(loss.item())\n",
    "    return loss_steps\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0101f5c562bf4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aa13e475b1ef81a2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001  Best Val Acc: 0.3220  Best Loss: 1.9422  \n",
      "Epoch: 020  Best Val Acc: 0.7730  Best Loss: 0.1375  \n",
      "Epoch: 040  Best Val Acc: 0.7810  Best Loss: 0.0037  \n",
      "Epoch: 060  Best Val Acc: 0.7870  Best Loss: 0.0026  \n",
      "Epoch: 080  Best Val Acc: 0.7870  Best Loss: 0.0026  \n",
      "Epoch: 100  Best Val Acc: 0.7910  Best Loss: 0.0027  \n",
      "Seed: 1, Test score: 0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2522759/2401252370.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load('best_model.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001  Best Val Acc: 0.3030  Best Loss: 1.9512  \n",
      "Epoch: 020  Best Val Acc: 0.7930  Best Loss: 0.1344  \n",
      "Epoch: 040  Best Val Acc: 0.7930  Best Loss: 0.1344  \n",
      "Epoch: 060  Best Val Acc: 0.7930  Best Loss: 0.1344  \n",
      "Epoch: 080  Best Val Acc: 0.7930  Best Loss: 0.1344  \n",
      "Epoch: 100  Best Val Acc: 0.7950  Best Loss: 0.0032  \n",
      "Seed: 2, Test score: 0.822\n",
      "Epoch: 001  Best Val Acc: 0.3070  Best Loss: 1.9403  \n",
      "Epoch: 020  Best Val Acc: 0.7850  Best Loss: 0.1681  \n",
      "Epoch: 040  Best Val Acc: 0.7890  Best Loss: 0.0033  \n",
      "Epoch: 060  Best Val Acc: 0.7910  Best Loss: 0.0028  \n",
      "Epoch: 080  Best Val Acc: 0.7970  Best Loss: 0.0030  \n",
      "Epoch: 100  Best Val Acc: 0.7970  Best Loss: 0.0030  \n",
      "Seed: 3, Test score: 0.819\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for seed in range(1, 4):\n",
    "    model = GraphSAGE(x.shape[1], output_dim, seed).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    # TODO: Change the call for train if needed\n",
    "    train(model, optimizer, torch.nn.CrossEntropyLoss(), data)\n",
    "    best_model = torch.load('best_model.pt')\n",
    "    model.load_state_dict(best_model)\n",
    "    curr_seed_score = evaluate(model, data.test_mask)\n",
    "    test_scores.append(curr_seed_score)\n",
    "    print(f\"Seed: {seed}, Test score: {curr_seed_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a14def337d9a7d0a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.821, 0.822, 0.819]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs236207",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
